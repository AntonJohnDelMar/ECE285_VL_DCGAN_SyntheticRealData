{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic vs Real Data for Autonomous Vehicle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f84bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from CGAN.CDCGAN import Generator, Discriminator\n",
    "from Classifier.ResNet import ResidualNetwork\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173a332",
   "metadata": {},
   "source": [
    "### Training our Conditional Deep Convolutional Generational Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image folder\n",
    "os.makedirs(\"sample_images\", exist_ok=True); \n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100; \n",
    "img_size = 32; \n",
    "channels = 1; \n",
    "n_classes = 10; \n",
    "embedding_dim = 50; \n",
    "batch_size = 64; \n",
    "n_epochs = 200; \n",
    "sample_interval = 400; \n",
    "lr = 0.0002; \n",
    "b1 = 0.5; \n",
    "b2 = 0.999; \n",
    "\n",
    "img_shape = (channels, img_size, img_size); \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); \n",
    "\n",
    "# Loss\n",
    "adversarial_loss = nn.BCELoss(); \n",
    "\n",
    "# Initialize models\n",
    "generator = Generator().to(device); \n",
    "discriminator = Discriminator().to(device); \n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2)); \n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2));  \n",
    "\n",
    "# Transform images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "# Load full dataset\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=\"Dataset/Train\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True); \n",
    "\n",
    "# Sample generator output\n",
    "def sample_image(n_row, batches_done):\n",
    "    z = torch.randn(n_row ** 2, latent_dim).to(device); \n",
    "    labels = torch.tensor([i for i in range(n_row) for _ in range(n_row)], dtype=torch.long).to(device); \n",
    "    gen_imgs = generator(z, labels); \n",
    "    save_image(gen_imgs.data, f\"sample_images/{batches_done}.png\", nrow=n_row, normalize=True); \n",
    "\n",
    "\n",
    "# Training\n",
    "g_losses = []; \n",
    "d_losses = []; \n",
    "for epoch in range(n_epochs):\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{n_epochs}\"); \n",
    "    epoch_g_loss = 0; \n",
    "    epoch_d_loss = 0; \n",
    "\n",
    "    for i, (imgs, labels) in enumerate(pbar):\n",
    "        real_imgs = imgs.to(device); \n",
    "        labels = labels.to(device); \n",
    "        batch_size = real_imgs.size(0); \n",
    "\n",
    "        valid = torch.ones(batch_size, 1, device=device); \n",
    "        fake = torch.zeros(batch_size, 1, device=device); \n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad();  \n",
    "        z = torch.randn(batch_size, latent_dim, device=device); \n",
    "        gen_labels = torch.randint(0, n_classes, (batch_size,), device=device); \n",
    "        gen_imgs = generator(z, gen_labels);  \n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs, gen_labels), valid); \n",
    "        g_loss.backward(); \n",
    "        optimizer_G.step(); \n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad(); \n",
    "        real_loss = adversarial_loss(discriminator(real_imgs, labels), valid);  \n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), gen_labels), fake); \n",
    "        d_loss = (real_loss + fake_loss) / 2; \n",
    "        d_loss.backward(); \n",
    "        optimizer_D.step(); \n",
    "\n",
    "        epoch_g_loss += g_loss.item(); \n",
    "        epoch_d_loss += d_loss.item(); \n",
    "\n",
    "        pbar.set_postfix(D_loss=f\"{d_loss.item():.4f}\", G_loss=f\"{g_loss.item():.4f}\"); \n",
    "\n",
    "        if (epoch * len(dataloader) + i) % sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=epoch * len(dataloader) + i);  \n",
    "\n",
    "    g_losses.append(epoch_g_loss / len(dataloader)); \n",
    "    d_losses.append(epoch_d_loss / len(dataloader)); \n",
    "\n",
    "\n",
    "plt.figure(); \n",
    "plt.plot(g_losses, linestye = '-'); \n",
    "plt.title(\"Generator Loss\"); \n",
    "plt.xlabel(\"Epochs\"); \n",
    "plt.ylabel(\"Loss\"); \n",
    "plt.savefig(\"Generator_Training_Loss.png\"); \n",
    "plt.close(); \n",
    "\n",
    "plt.figure(); \n",
    "plt.plot(d_losses, linestye = '-'); \n",
    "plt.title(\"Discriminator Loss\"); \n",
    "plt.xlabel(\"Epochs\"); \n",
    "plt.ylabel(\"Loss\"); \n",
    "plt.savefig(\"Discriminator_Training_Loss.png\"); \n",
    "plt.close(); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994329c",
   "metadata": {},
   "source": [
    "### Generating our Synthetic Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42421ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_per_class(generator, latent_dim, n_classes, total_per_class = 500, save_dir = \"Generated_Dataset/Train\"):\n",
    "    generator.eval(); # Evaluation mode\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok = True); \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for class_label in range(n_classes):\n",
    "            class_dir = os.path.join(save_dir, f\"{class_label}\"); \n",
    "            os.makedirs(class_dir, exist_ok = True); \n",
    "\n",
    "            num_generated = 0; \n",
    "            while num_generated < total_per_class:\n",
    "                batch_size = min(64, total_per_class - num_generated); \n",
    "                z = torch.randn(batch_size, latent_dim).to(device); \n",
    "                labels = torch.full((batch_size,), class_label, dtype=torch.long).to(device); \n",
    "\n",
    "                gen_imgs = generator(z, labels); \n",
    "\n",
    "                for i in range(batch_size):\n",
    "                    img_tensor = gen_imgs[i].cpu(); \n",
    "                    img_path = os.path.join(class_dir, f\"{i}.png\"); \n",
    "                    vutils.save_image(img_tensor, img_path, normalize = True); \n",
    "\n",
    "                num_generated += batch_size; \n",
    "\n",
    "generate_images_per_class(generator, latent_dim=latent_dim, n_classes = 15, total_per_class = 800, save_dir = \"Generated_Dataset/Train\"); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our Residual Network on Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Fake Dataset\n",
    "\n",
    "# Dataset path\n",
    "data_dir = \"Generated_Dataset/Train\"; \n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "# Load full dataset\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=data_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model\n",
    "num_classes = len(dataset.classes); \n",
    "resnet_fake = ResidualNetwork(\n",
    "    in_channel=3,\n",
    "    channel_1=64,\n",
    "    channel_2=64,\n",
    "    channel_3=128,\n",
    "    channel_4=256,\n",
    "    channel_5=512,\n",
    "    number_classes=num_classes\n",
    ").to(device); \n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(); \n",
    "optimizer = optim.Adam(resnet_fake.parameters(), lr=1e-4); \n",
    "\n",
    "# Training loop\n",
    "epochs = 10; \n",
    "training_losses = []; \n",
    "for epoch in range(epochs):\n",
    "    resnet_fake.train();  \n",
    "    running_loss = 0.0; \n",
    "    correct = 0; \n",
    "    total = 0; \n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device); \n",
    "\n",
    "        # Forward\n",
    "        outputs = resnet_fake(inputs); \n",
    "        loss = criterion(outputs, labels); \n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad(); \n",
    "        loss.backward(); \n",
    "        optimizer.step(); \n",
    "\n",
    "        # Metrics\n",
    "        running_loss += loss.item() * inputs.size(0); \n",
    "        _, predicted = torch.max(outputs, 1); \n",
    "        total += labels.size(0); \n",
    "        correct += (predicted == labels).sum().item(); \n",
    "\n",
    "    epoch_loss = running_loss / len(dataset); \n",
    "    training_losses.append(); \n",
    "    epoch_acc = correct / total; \n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\"); \n",
    "\n",
    "\n",
    "plt.figure(); \n",
    "plt.plot(training_losses, linestye = '-'); \n",
    "plt.title(\"Training Loss\"); \n",
    "plt.xlabel(\"Epochs\"); \n",
    "plt.ylabel(\"Loss\"); \n",
    "plt.savefig(\"ResNet_Loss_Real.png\"); \n",
    "plt.close(); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our Residual Network on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Real Dataset\n",
    "\n",
    "# Dataset path\n",
    "data_dir = \"Dataset/Train\"; \n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "]); \n",
    "\n",
    "# Load full dataset\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=data_dir,\n",
    "    transform=transform\n",
    "); \n",
    "\n",
    "# Split into train/test using fixed seed\n",
    "n_total = len(dataset); \n",
    "indices = np.random.RandomState(seed=42).permutation(n_total); \n",
    "split = int(n_total * 0.8); \n",
    "train_indices = indices[:split]; \n",
    "test_indices = indices[split:];  \n",
    "\n",
    "train_dataset = Subset(dataset, train_indices); \n",
    "test_dataset = Subset(dataset, test_indices); \n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True); \n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False); \n",
    "\n",
    "# Model\n",
    "num_classes = len(dataset.classes); \n",
    "resnet_real = ResidualNetwork(\n",
    "    in_channel=3,\n",
    "    channel_1=64,\n",
    "    channel_2=64,\n",
    "    channel_3=128,\n",
    "    channel_4=256,\n",
    "    channel_5=512,\n",
    "    number_classes=num_classes\n",
    ").to(device); \n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(); \n",
    "optimizer = optim.Adam(resnet_real.parameters(), lr=1e-4); \n",
    "\n",
    "# Training loop\n",
    "epochs = 10; \n",
    "training_losses = []; \n",
    "for epoch in range(epochs):\n",
    "    resnet_real.train();  \n",
    "    running_loss = 0.0; \n",
    "    correct = 0; \n",
    "    total = 0; \n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device); \n",
    "\n",
    "        # Forward\n",
    "        outputs = resnet_real(inputs); \n",
    "        loss = criterion(outputs, labels); \n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad(); \n",
    "        loss.backward(); \n",
    "        optimizer.step(); \n",
    "\n",
    "        # Metrics\n",
    "        running_loss += loss.item() * inputs.size(0); \n",
    "        _, predicted = torch.max(outputs, 1); \n",
    "        total += labels.size(0); \n",
    "        correct += (predicted == labels).sum().item(); \n",
    "\n",
    "    epoch_loss = running_loss / len(dataset); \n",
    "    training_losses.append(); \n",
    "    epoch_acc = correct / total; \n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\"); \n",
    "\n",
    "\n",
    "plt.figure(); \n",
    "plt.plot(training_losses, linestye = '-'); \n",
    "plt.title(\"Training Loss\"); \n",
    "plt.xlabel(\"Epochs\"); \n",
    "plt.ylabel(\"Loss\"); \n",
    "plt.savefig(\"ResNet_Loss_Real.png\"); \n",
    "plt.close(); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, dataloader, device):\n",
    "    model.eval(); \n",
    "    correct = 0; \n",
    "    total = 0; \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device); \n",
    "\n",
    "            outputs = model(images); \n",
    "            _, predicted = torch.max(outputs, 1); \n",
    "\n",
    "            correct += (predicted == labels).sum().item(); \n",
    "            total += labels.size(0); \n",
    "\n",
    "    return correct / total; \n",
    "\n",
    "acc_fake = test_accuracy(resnet_fake, test_loader, device); \n",
    "print(\"ResNet Test Accuracy (Trained on Synthetic Data): \", acc_fake); \n",
    "acc_real = test_accuracy(resnet_real, test_loader, device); \n",
    "print(\"ResNet Test Accuracy (Trained on Real Data): \", acc_real); \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
